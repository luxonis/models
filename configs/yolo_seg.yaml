logger:
  project_name: ml-ops-train
  save_directory: output
  is_tensorboard: True
  is_wandb: False #True #False
  wandb_entity: Luxonis
  is_mlflow: False

model:
  name: YoloV6-n
  type: YoloV6-n # uncomment this to use predefined model
  pretrained: #/home/paperspace/models/output/brown-pheasant-25/best_val_metric/val_map=0.3097_val_loss=0.1417_epoch=109_YoloV6-n.ckpt
  params: # only take into account if using predefined model
    n_classes: 1

  backbone:
    name: EfficientRep
    pretrained:
    params:
      channels_list: [64, 128, 256, 512, 1024]
      num_repeats: [1, 6, 12, 18, 6]
      depth_mul: 0.33
      width_mul: 0.25

  neck:
    name: RepPANNeck
    params:
      channels_list: [256, 128, 128, 256, 256, 512]
      num_repeats: [12, 12, 12, 12]
      depth_mul: 0.33
      width_mul: 0.25

  heads:
    - name: YoloV6Head
      params:
        n_classes: 1
        n_layers: 3
        reg_max: 0
      loss: 
        name: YoloV6Loss
        params:
          n_classes: 1
          iou_type: siou

  additional_heads:
    - name: SegmentationHead
      params:
        n_classes: 1
      loss: 
        name: FocalLoss
        params:

dataset:
  local_path: /home/klemen/luxonis/model_debug/datasets/coco-2017-person
  s3_path: #s3://luxonis/datasets/demo

train:
  image_size: [128,128] #[128, 128]
  batch_size: 8 #32
  accumulate_grad_batches: #2 # number of batches we do before doing backward pass
  epochs: 400
  n_workers: 4
  n_metrics:  # compute metrics on train set every n_metric epochs
  eval_interval: 10
  
  early_stopping:
    monitor: val_loss
    mode: min
    patience: 10

augmentations:
  - name: HorizontalFlip
    params:
      p: 0.4
  - name: Rotate
    params:
      limit: 15
  - name: GaussianBlur
    params:
      p: 0.3

optimizer:
  name: SGD
  params:
    lr: 0.02
    momentum: 0.937
    nesterov: True
    weight_decay: 0.0005

scheduler:
  name: CosineAnnealingLR
  params:
    T_max: 400 #120000
    eta_min: 0
  
